version: "3"

services:
# =============== MASTER =================
  hdfs-namenode:
    image: kevinity310/hadoop-namenode:dev
    container_name: hdfs-namenode
    restart: always
    ports:
      - 9870:9870
      - 9010:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:9000
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

  hdfs-datanode:
    image: kevinity310/hadoop-datanode:dev
    container_name: hdfs-datanode
    restart: always
    volumes:
      - hadoop_datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://hdfs-namenode:9000
    ports:
      - "9864:9864"
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

  yarn-resourcemanager:
    image: kevinity310/hadoop-resourcemanager:dev
    container_name: yarn-resourcemanager
    ports:
      - "8088:8088"
    restart: always
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:9000 hdfs-namenode:9870 hdfs-datanode:9864"
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop
      
  yarn-historyserver:
    image: kevinity310/hadoop-historyserver:dev
    container_name: yarn-historyserver
    restart: always
    ports:
      - "8188:8188"
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:9000 hdfs-namenode:9870 hdfs-datanode:9864 yarn-resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

  pg-metastore:
    image: kevinity310/pg-metastore:dev 
    container_name: pg-metastore
    ports:
      - "5432:5432"
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

  hive-metastore:
    image: kevinity310/hive:dev 
    command: 'hive --service metastore --verbose'
    container_name: hive-metastore
    ports:
      - "9083:9083"
    environment:
      SERVICE_PRECONDITION: "pg-metastore:5432 hdfs-namenode:9000 hdfs-datanode:9864"
    healthcheck:
        test:  ["CMD-SHELL", "nc -z localhost 9083 || exit 1"]
        interval: 30s
        timeout: 10s
        retries: 3
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

  hive-server2:
    container_name: hive-server2
    command: 'hive --service hiveserver2 --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.root.logger=DEBUG,console'
    image: kevinity310/hive:dev
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:9000 hdfs-datanode:9864 hive-metastore:9083"
    ports:
      - "10000:10000"
      - "10001:10001"
      - "10002:10002"
    extra_hosts:
      - "hive-metastore:172.20.0.6" # please change to your hive-metastore container ip
    depends_on:
      - hive-metastore
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:10002"]
      interval: 30s
      timeout: 10s
      retries: 3
    env_file:
        - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 1
          memory: 1g
    networks:
      - kafka-hadoop

# 24/03/01 10:15:23 [main]: INFO thrift.ThriftCLIService: Starting ThriftBinaryCLIService on port 10000 with 5...500 worker threads (kalau ada ini berarti berhasil)

  # presto-coordinator:
  #   image: shawnzhu/prestodb:0.181
  #   container_name: presto-coordinator
  #   ports:
  #     - "8089:8089"

# =============== EDGE =================

  # jupyter_dev:
  #   image: kevinity310/jupyter-notebook:dev
  #   container_name: jupyter_dev
  #   ports:
  #     - "8889:8888"
  #   env_file:
  #     - ./hadoop-port-dev.env

  zeppelin:
    image: kevinity310/zeppelin:dev
    container_name: zeppelin
    ports:
      - "9995:9995"
    environment:
          SERVICE_PRECONDITION: "hdfs-namenode:9000 hdfs-namenode:9870 hdfs-datanode:9864 yarn-resourcemanager:8088"
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 2
          memory: 1g
    networks:
      - kafka-hadoop

# =============== WORKER =================

  yarn-nodemanager:
    image: kevinity310/hadoop-nodemanager:dev
    container_name: yarn-nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "hdfs-namenode:9000 hdfs-namenode:9870 hdfs-datanode:9864 yarn-resourcemanager:8088"
    env_file:
      - ./hadoop-port-dev.env
    deploy:
      resources:
        limits:
          cpus: 8
          memory: 8g
    networks:
      - kafka-hadoop

volumes:
  hadoop_namenode:
  hadoop_datanode:
  hadoop_historyserver:


networks:
  kafka-hadoop:
    external: true