# HADOOP_CLASSPATH=/opt/hive-3.1.3/lib/lib/hive-exec-3.1.3.jar

CORE_CONF_fs_defaultFS=hdfs://hdfs-namenode:9000
CORE_CONF_hadoop_http_staticuser_user=root
CORE_CONF_hadoop_proxyuser_hue_hosts=*
CORE_CONF_hadoop_proxyuser_hue_groups=*
CORE_CONF_io_compression_codecs=org.apache.hadoop.io.compress.SnappyCodec
CORE_CONF_hadoop_proxyuser_root_groups=*
CORE_CONF_hadoop_proxyuser_root_hosts=*
CORE_CONF_hadoop_proxyuser_username_groups=*
CORE_CONF_hadoop_proxyuser_username_hosts=*

# CORE_CONF_hadoop.tmp.dir=
# CORE_CONF_hadoop.security.authentication=simple
# CORE_CONF_hadoop.security.authorization=false
# CORE_CONF_hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
# CORE_CONF_hadoop.security.groups.cache.secs=300
# CORE_CONF_hadoop.security.key.provider.path=URL
# CORE_CONF_hadoop.security.key.provider.path.ftp=org.apache.hadoop.fs.ftp.FtpKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.http=org.apache.hadoop.fs.http.HttpKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.jceks=org.apache.hadoop.fs.jceks.JceksKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.localjceks=org.apache.hadoop.fs.local.LocalJceksKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.pkcs12=org.apache.hadoop.fs.pkcs12.PKCS12KeyProvider
# CORE_CONF_hadoop.security.key.provider.path.ssh=org.apache.hadoop.fs.ssh.SshKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.swarm=org.apache.hadoop.fs.swarm.SwarmKeyProvider
# CORE_CONF_hadoop.security.key.provider.path.test=org.apache.hadoop.fs.TestKeyProvider

HDFS_CONF_dfs_webhdfs_enabled=true
HDFS_CONF_dfs_permissions_enabled=false
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
HDFS_CONF_hadoop_http_filter_initializers=org.apache.hadoop.security.HttpCrossOriginFilterInitializer

# Issue : Apache Tez Job fails due to java.lang.NumberFormatException for input string: "30s"
# https://stackoverflow.com/questions/61369722/apache-tez-job-fails-due-to-java-lang-numberformatexception-for-input-string-3
# =======================================================
HDFS_CONF_dfs_namenode_decommission_interval=30
HDFS_CONF_dfs_client_datanode___restart_timeout=30
# =======================================================

YARN_CONF_yarn_acl_enable=false
YARN_CONF_yarn_log___aggregation___enable=true
YARN_CONF_yarn_log_server_url=http://yarn-historyserver:8188/applicationhistory/logs/
YARN_CONF_yarn_resourcemanager_recovery_enabled=true
YARN_CONF_yarn_resourcemanager_store_class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
YARN_CONF_yarn_resourcemanager_scheduler_class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___mb=8192
YARN_CONF_yarn_scheduler_capacity_root_default_maximum___allocation___vcores=4
YARN_CONF_yarn_resourcemanager_fs_state___store_uri=/rmstate
YARN_CONF_yarn_resourcemanager_system___metrics___publisher_enabled=true

YARN_CONF_yarn_resourcemanager_hostname=yarn-resourcemanager
YARN_CONF_yarn_resourcemanager_address=yarn-resourcemanager:8032
YARN_CONF_yarn_resourcemanager_scheduler_address=yarn-resourcemanager:8030
YARN_CONF_yarn_resourcemanager_resource__tracker_address=yarn-resourcemanager:8031

YARN_CONF_yarn_timeline___service_enabled=true
YARN_CONF_yarn_timeline___service_generic___application___history_enabled=true
YARN_CONF_yarn_timeline___service_hostname=yarn-historyserver
YARN_CONF_mapreduce_map_output_compress=true
YARN_CONF_mapred_map_output_compress_codec=org.apache.hadoop.io.compress.SnappyCodec
YARN_CONF_yarn_nodemanager_resource_memory___mb=8192
YARN_CONF_yarn_nodemanager_resource_cpu___vcores=8
YARN_CONF_yarn_nodemanager_disk___health___checker_max___disk___utilization___per___disk___percentage=98.5
YARN_CONF_yarn_nodemanager_remote___app___log___dir=/app-logs
YARN_CONF_yarn_nodemanager_aux___services=mapreduce_shuffle

YARN_CONF_yarn_timeline___service_http___cross___origin_enabled=true

MAPRED_CONF_mapreduce_framework_name=yarn
MAPRED_CONF_mapred_child_java_opts=-Xmx4096m
MAPRED_CONF_mapreduce_map_memory_mb=1024
MAPRED_CONF_mapreduce_reduce_memory_mb=2048
MAPRED_CONF_mapreduce_map_java_opts=-Xmx3072m
MAPRED_CONF_mapreduce_reduce_java_opts=-Xmx6144m
MAPRED_CONF_yarn_app_mapreduce_am_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
MAPRED_CONF_mapreduce_map_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/
MAPRED_CONF_mapreduce_reduce_env=HADOOP_MAPRED_HOME=/opt/hadoop-3.2.1/

# For Hive Configuration
HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false

# HIVE Metastore
HIVE_SITE_CONF_hive_metastore_local=false
HIVE_SITE_CONF_hive_metastore_warehouse_dir=/apps/hive/warehouse
HIVE_SITE_CONF_hive_metastore_port=9083
HIVE_SITE_CONF_hive_metastore_uris=thrift://hive-metastore:9083

HIVE_SITE_CONF_javax_jdo_option_ConnectionURL=jdbc:postgresql://pg-metastore:5432/hivemetastore
HIVE_SITE_CONF_javax_jdo_option_ConnectionDriverName=org.postgresql.Driver
HIVE_SITE_CONF_javax_jdo_option_ConnectionUserName=hive
HIVE_SITE_CONF_javax_jdo_option_ConnectionPassword=hive
HIVE_SITE_CONF_datanucleus_autoCreateSchema=true
HIVE_SITE_CONF_datanucleus_fixedDatastore=true
HIVE_SITE_CONF_datanucleus_autoCreateTables=true
HIVE_SITE_CONF_hive_metastore_client_connect_retry_delay=5
HIVE_SITE_CONF_hive_metastore_client_socket_timeout=1800

# Hive server2
HIVE_SITE_CONF_hive_execution_engine=tez
HIVE_SITE_CONF_hive_server2_enable_doAs=false
HIVE_SITE_CONF_hive_server2_thrift_http_port=10001
HIVE_SITE_CONF_hive_server2_thrift_port=10000
HIVE_SITE_CONF_hive_server2_transport_mode=binary
HIVE_SITE_CONF_hive_server2_webui_port=10002
HIVE_SITE_CONF_mapreduce_input_fileinputformat_input_dir_recursive=true
HIVE_SITE_CONF_hive_root_logger=DEBUG,console
HIVE_SITE_CONF_hive_server2_thrift_http_max_worker_threads=500
HIVE_SITE_CONF_hive_server2_thrift_http_min_worker_threads=5
HIVE_SITE_CONF_hive___timeline___logging___enabled=true

HIVE_SITE_CONF_hive_exec_post_hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
HIVE_SITE_CONF_hive_exec_pre_hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
HIVE_SITE_CONF_hive_exec_failure_hooks=org.apache.hadoop.hive.ql.hooks.ATSHook
HIVE_SITE_CONF_hive_timeline_logging_enabled=true

# Hive Map Reduce
HIVE_SITE_CONF_hive_exec_timeout_max=-1
HIVE_SITE_CONF_hive_server2_idle_session_timeout=-1
HIVE_SITE_CONF_hive_query_timeout=-1

# ERROR: “FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.StatsTask” while writing to a Hive partitioned target in the native environment
# https://community.cloudera.com/t5/Support-Questions/org-apache-hadoop-hive-ql-exec-StatsTask-MetaException/td-p/315068
# https://knowledge.informatica.com/s/article/ERROR-FAILED-Execution-Error-return-code-1-from-org-apache-hadoop-hive-ql-exec-StatsTask-occurs-when-you-write-to-a-Hive-partitioned-target-in-the-native-environment-and-the-mapping-contains-an-expression-transformation-with-TO-Date-function?language=en_US
# ===========================
HIVE_SITE_CONF_hive_txn_stats_enabled=false
HIVE_SITE_CONF_hive_stats_autogather=false 
# ===========================

# HIVE_SITE_CONF_hive_server2_transport_mode=http
# HIVE_SITE_CONF_hive_server2_thrift_http_path=cliservice
# HIVE_SITE_CONF_hive_server2_thrift_bind_host=hive-server2

# HIVE_SITE_CONF_hive_server2_authentication=NOSASL
# HIVE_SITE_CONF_hive_server2_thrift_bind_host=localhost
# HIVE_SITE_CONF_hive_metastore_event_db_notification_api_auth=false

# hive.server2.thrift.http.path=cliservice
# hive.server2.use.SSL=true
# hive.server2.keystore.path=Set this to your keystore path.
# hive.server2.keystore.password=Set this to your keystore password.


# HIVE_SITE_CONF_spark_master=yarn
# HIVE_SITE_CONF_spark_eventLog_enabled=true
# HIVE_SITE_CONF_spark_serializer=org.apache.spark.serializer.KryoSerializer
# HIVE_SITE_CONF_spark_eventLog_dir=hdfs:///user/spark/spark2-history/
# HIVE_SITE_CONF_spark_driver_memory=512m
# HIVE_SITE_CONF_spark_executor_memory=1g
# HIVE_SITE_CONF_spark_executor_instances=2
# HIVE_SITE_CONF_spark_executor_cores=2
# HIVE_SITE_CONF_spark_network_timeout=600s # test
# HIVE_SITE_CONF_spark_yarn=hdfs://localhost:8020/spark-jars/*
# HIVE_SITE_CONF_spark_driver_extraClassPath=/opt/hive-3.1.3/lib/*


TEZ_CONF_tez_lib_uris=hdfs://hdfs-namenode:9000/apps/tez/tez.tar.gz
# TEZ_CONF_tez_staging___dir=/tmp/${user.name}/staging
TEZ_CONF_tez_task_resource_cpu_vcores=1
TEZ_CONF_tez_task_resource_memory_mb=1024
TEZ_CONF_tez_am_resource_cpu_vcores=1
TEZ_CONF_tez_am_resource_memory_mb=1024
TEZ_CONF_tez_task___specific_log_level=DEBUG;org.apache.hadoop.ipc=INFO;org.apache.hadoop.security=INFO
TEZ_CONF_tez_tez___ui_history___url_base=http://hdfs-namenode:9999/tez-ui
TEZ_CONF_tez_history_logging_service_class=org.apache.tez.dag.history.logging.ats.ATSHistoryLoggingService
TEZ_CONF_tez_am_acls_enabled=true # Configuration to enable/disable ACL checks.
TEZ_CONF_tez_task_log_level=DEBUG
TEZ_CONF_tez_am_log_level=DEBUG



# TEZ_CONF_das_execution___framework=Tez
# TEZ_CONF_das_debug_tasks_logs_collect_force=true
TEZ_CONF_tez_allow_disabled_timeline___domains=true
TEZ_CONF_tez_am_history_logging_enabled=true
TEZ_CONF_yarn_timeline___service_enabled=true
TEZ_CONF_tez_dag_history_logging_enabled=true
TEZ_CONF_tez_allow_disabled_timeline___domains=true
TEZ_CONF_tez_yarn_ats_enabled=true
TEZ_CONF_tez_runtime_convert_user___payload_to_history___text=true
TEZ_CONF_tez_dag_recovery_enabled=true
TEZ_CONF_tez_dag_recovery_io_buffer_size=2048 # Int value. Size in bytes for the IO buffer size while processing the recovery file.Expert level setting
TEZ_CONF_tez_dag_recovery_flush_interval_secs=30 # Int value. Interval, in seconds, between flushing recovery data to the recovery log.
TEZ_CONF_tez_dag_recovery_max_unflushed_events=100 # Number of recovery events to buffer before flushing them to the recovery log.
TEZ_CONF_tez_task_heartbeat_timeout_check___ms=30000
TEZ_CONF_tez_task_timeout___ms=300000 # Int value. Time interval, in milliseconds, within which a task must heartbeat to the app masterbefore its considered lost. | Expert level setting.
# TEZ_CONF_tez_am_client_am_port___range= 
TEZ_CONF_tez_am_client_heartbeat_timeout_secs=-1 
TEZ_CONF_tez_am_client_am_thread___count=2 # Number of threads to handle client RPC requests. Expert level setting.
TEZ_CONF_tez_am_commit___all___outputs___on___dag___success=true #
TEZ_CONF_tez_am_containerlauncher_thread___count___limit=500 # Upper limit on the number of threads user to launch containers in the app master. Expert level setting.
TEZ_CONF_tez_am_container_idle_release_timeout___max_millis=10000  #The maximum amount of time to hold on to a container if no task can be assigned to it immediately. Only active when reuse is e3 nabled
TEZ_CONF_tez_am_container_idle_release___timeout___min_millis=5000 #  The minimum amount of time to hold on to a container that is idle. Only active when reuse is enabled. Set to -1 to never release idle containers (not recommended).
TEZ_CONF_tez_am_container_reuse_enabled=true # Configuration to specify whether container should be reused across tasks. This improves performance by not incurring recurring launch overheads.
TEZ_CONF_tez_am_container_reuse_locality_delay___allocation___millis=250 # The amount of time to wait before assigning a container to the next level of locality. NODE -&gt; RACK -&gt; NON_LOCAL. Delay scheduling parameter. Expert level setting.
TEZ_CONF_tez_am_container_reuse_new___containers_enabled=false # 
TEZ_CONF_tez_am_container_reuse_non___local___fallback_enabled=false #  Whether to reuse containers for non-local tasks. Active only if reuse is enabled. Turning this on can severely affect locality and can be bad for jobs with high data  volume being read from the primary data sources.
TEZ_CONF_tez_am_container_reuse_rack___fallback_enabled=true # Whether to reuse containers for rack local tasks. Active only if reuse is enabled.

# TEZ_CONF_tez_am_credentials___merge=false # If true then Tez will add the ApplicationMaster credentials to all task credentials.
TEZ_CONF_tez_am_dag_cleanup_on_completion=false # Instructs AM to delete Dag directory upon completion
TEZ_CONF_tez_am_dag_deletion_thread___count___limit=10 # Upper limit on the number of threads used to delete DAG directories on nodes.
TEZ_CONF_tez_am_dag_scheduler_class=org.apache.tez.dag.app.dag.impl.DAGSchedulerNaturalOrder # The class to be used for DAG Scheduling. Expert level setting.
TEZ_CONF_tez_am_deletion_tracker_class=org.apache.tez.dag.app.launcher.DeletionTrackerImpl
TEZ_CONF_tez_am_disable_client___version___check=false # Configuration to disable the client version check. This is useful for testing and development purposes.
TEZ_CONF_tez_am_inline_task_execution_enabled=false # Tez AM Inline Mode flag. Not valid till Tez-684 get checked-in
# TEZ_CONF_tez_am_inline_task_execution_max___tasks=1 # The maximium number of tasks running in parallel within the app master process.
# TEZ_CONF_tez_am_launch_cluster___default_cmd___opts=-server -Djava.net.preferIPv4Stack=true -Dhadoop.metrics.log.level=DEBUG 

# TEZ_CONF_tez_am_launch_cmd___opts=-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC # 
# TEZ_CONF_tez_am_launch_env= #
# TEZ_CONF_tez_am_legacy_speculative_single_task_vertex_timeout=-1 # <unstable>true</unstable>

# TEZ_CONF_tez_am_legacy_speculative_slowtask_threshold= #Specifies how many standard deviations away from the mean task execution time should be considered as an outlier/slow task. <unstable>true</unstable>

TEZ_CONF_tez_am_max_allowed_time_sec_for___read___error=300 # 
TEZ_CONF_tez_am_max_app_attempts=2 # The maximum number of application attempts for the Tez AM. Expert level setting.
TEZ_CONF_tez_am_maxtaskfailures_per_node=10
# TEZ_CONF_tez_am_minimum_allowed_speculative_tasks=10 #<unstable>true</unstable>
# TEZ_CONF_tez_am_modify___acls=
TEZ_CONF_tez_am_node___blacklisting_enabled=true
TEZ_CONF_tez_am_node___blacklisting_ignore___threshold___node___percent=33
TEZ_CONF_tez_am_node___unhealthy___reschedule___tasks=false #change
TEZ_CONF_tez_am_preemption___heartbeats___between___preemptions=3
TEZ_CONF_tez_am_preemption_max_wait___time___ms=6000
TEZ_CONF_tez_am_preemption_percentage=10
# TEZ_CONF_tez_am_proportion_running_tasks_speculatable=0.1 # <unstable>true</unstable>
TEZ_CONF_tez_am_proportion_total_tasks_speculatable=0.01
TEZ_CONF_tez_am_am___rm_heartbeat_interval___ms_max=1000 # Expert level setting.
TEZ_CONF_tez_am_session_min_held__containers=0
TEZ_CONF_tez_am_mode_session=false # session mode reuse recommended true
TEZ_CONF_tez_am_shuffle_auxiliary___service_id=mapreduce_shuffle
TEZ_CONF_tez_am_soonest_retry_after_no_speculate=1000
TEZ_CONF_tez_am_soonest_retry_after_speculate=15000
# TEZ_CONF_tez_am_speculation_enabled=false # <unstable>true</unstable>
# TEZ_CONF_tez_staging___dir=
TEZ_CONF_tez_am_staging_scratch___data_auto___delete=true
TEZ_CONF_tez_am_task_listener_thread___count=30
TEZ_CONF_tez_am_task_max_failed_attempts=4
TEZ_CONF_tez_am_task_reschedule_higher_priority=true
TEZ_CONF_tez_am_task_reschedule_relaxed_locality=
# TEZ_CONF_tez_task_launch_cluster___default_env=
# TEZ_CONF_tez_task_launch_cmd___opts=-XX:+PrintGCDetails -verbose:gc -XX:+PrintGCTimeStamps -XX:+UseNUMA -XX:+UseParallelGC
# TEZ_CONF_tez_task_launch_env=
TEZ_CONF_tez_task_max___events___per___heartbeat=500
TEZ_CONF_tez_task_max___event___backlog=10000
TEZ_CONF_tez_task_progress_stuck_interval___ms=-1
# TEZ_CONF_tez_task_resource_calculator_process___tree_class=true # <unstable>true</unstable>

# TEZ_CONF_tez_task_scale_memory_additional___reservation_fraction_max= #<unstable>true</unstable>
# TEZ_CONF_tez_task_scale_memory_additional___reservation_fraction_per___io=true # <unstable>true</unstable>
TEZ_CONF_tez_task_scale_memory_allocator_class=org.apache.tez.runtime.library.resources.WeightedScalingMemoryDistributor
TEZ_CONF_tez_task_scale_memory_enabled=true # <unstable>true</unstable>
# TEZ_CONF_tez_task_scale_memory_reserve___fraction=0.3 #<unstable>true</unstable>
# TEZ_CONF_tez_task_scale_memory_ratios= # <unstable>true</unstable>
# TEZ_CONF_tez_task___specific_launch_cmd___opts= # <unstable>true</unstable>
# TEZ_CONF_tez_task___specific_launch_cmd___opts_list= # <unstable>true</unstable>
TEZ_CONF_tez_test_minicluster_app_wait_on_shutdown_secs=30
TEZ_CONF_tez_user_classpath_first=true
# TEZ_CONF_tez_use_cluster_hadoop___libs=false
TEZ_CONF_tez_yarn_ats_acl_domains_auto___create=true
TEZ_CONF_tez_yarn_ats_event_flush_timeout_millis=-1
TEZ_CONF_tez_yarn_ats_max_events_per_batch=5
TEZ_CONF_tez_yarn_ats_max_polling_time_per_event_millis=10

# For Spark Configuration
SPARK_CONFING_spark_master=yarn
SPARK_CONFING_spark_driver_memory=1g
SPARK_CONFING_spark_executor_memory=1g
SPARK_CONFING_spark_executor_instances=2
SPARK_CONFING_spark_executor_cores=2
SPARK_CONFING_spark_serializer=org.apache.spark.serializer.KryoSerializer

SPARK_CONFING_spark_eventLog_dir=hdfs:///apps/spark/spark2-history/
SPARK_CONFING_spark_eventLog_enabled=true
SPARK_CONFING_spark_executor_extraJavaOptions=-XX:+UseNUMA
SPARK_CONFING_spark_executor_extraJavaOptions=-XX:+UseNUMA
# SPARK_CONFING_spark_executor_extraLibraryPath=/usr/yava/current/hadoop-client/lib/native:/usr/yava/current/hadoop-client/lib/native/Linux-amd64-64
SPARK_CONFING_spark_history_fs_cleaner_enabled=true
SPARK_CONFING_spark_history_fs_cleaner_interval=7d
SPARK_CONFING_spark_history_fs_cleaner_maxAge=90d
# SPARK_CONFING_spark_history_fs_logDirectory=hdfs:///apps/spark/spark2-history/
SPARK_CONFING_spark_history_kerberos_keytab=none 
SPARK_CONFING_spark_history_kerberos_principal=none
SPARK_CONFING_spark_history_provider=org.apache.spark.deploy.history.FsHistoryProvider
SPARK_CONFING_spark_history_ui_port=18081
SPARK_CONFING_spark_io_compression_lz4_blockSize=128kb
SPARK_CONFING_spark_shuffle_file_buffer=1m
SPARK_CONFING_spark_shuffle_io_backLog=2048
SPARK_CONFING_spark_shuffle_io_serverThreads=128
SPARK_CONFING_spark_shuffle_unsafe_file_output_buffer=5m

# Spark connect Hive Metastore
SPARK_CONFING_spark_sql_warehouse_dir=hdfs:///apps/hive/warehouse
SPARK_CONFING_spark_hadoop_hive_metastore_uris=thrift://hive-metastore:9083

SPARK_CONFING_spark_sql_autoBroadcastJoinThreshold=-1
SPARK_CONFING_spark_sql_broadcastTimeout=300
SPARK_CONFING_spark_sql_catalogImplementation=hive
SPARK_CONFING_spark_sql_hive_convertMetastoreOrc=true

# SPARK_CONFING_spark_sql_hive_metastore_jars=/usr/yava/current/spark2-client/standalone-metastore/*:/usr/yava/current/tez-client/*:/usr/yava/current/spark2-client/jars/*

SPARK_CONFING_spark_sql_hive_metastore_version=2.3.9

SPARK_CONFING_spark_sql_orc_filterPushdown=true
SPARK_CONFING_spark_sql_orc_impl=native
SPARK_CONFING_spark_sql_statistics_fallBackToHdfs=true
SPARK_CONFING_spark_unsafe_sorter_spill_reader_buffer_size=1m
# SPARK_CONFING_spark_yarn_historyServer_address=0.0.0.0:18081
SPARK_CONFING_spark_yarn_queue=default
SPARK_CONFING_spark_network_timeout=600s
SPARK_CONFING_spark_driver_extraClassPath=/opt/hive-3.1.3/lib/*

